{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica de reconstrucción.  Parte II. Visión estéreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visión Computaciona <br>\n",
    "Practica 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este enunciado está en el archivo \"PracticaStereo.ipynb\" o su versión \"pdf\" que puedes encontrar en el Aula Virtual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetivos de esta práctica son:\n",
    "* reconstruir puntos de una escena a partir de una serie de correspondencias manuales entre dos imágenes calibradas;\n",
    "* determinar la geometría epipolar de un par de cámaras a partir de sus matrices de proyección;\n",
    "* implementar la búsqueda automática de correspondencias que use las restricciones impuestas por la geometría epipolar, aplicando para ello métodos de cortes de grafos;\n",
    "* realizar una reconstrucción densa de la escena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta práctica es necesario disponer del siguiente software:\n",
    "* Python 2.7 ó 3.X \n",
    "* Jupyter http://jupyter.org/.\n",
    "* Las librerías científicas de Python: NumPy, SciPy, y Matplotlib.\n",
    "* La librería OpenCV\n",
    "* La librería PyMaxFlow\n",
    "\n",
    "El material necesario para la práctica se puede descargar del Aula Virtual en la carpeta ``MaterialesPractica`` del tema de visión estéreo. Esta\n",
    "carpeta contiene:\n",
    "* Una serie de pares estéreo en el directorio images;\n",
    "el sufijo del fichero indica si corresponde a la cámara\n",
    "izquierda (_left) o a la derecha (_right). Bajo el\n",
    "directorio ``rectif`` se encuentran varios pares estéreo\n",
    "rectificados.\n",
    "* Un conjunto de funciones auxiliares de ``Python`` en \n",
    "el módulo ``misc.py``. La descripción de las funciones\n",
    "puede consultarse con el comando help o leyendo\n",
    "su código fuente.\n",
    "* El archivo ``cameras.npz`` con las matrices de proyección del par de cámaras con el que se tomaron todas las imágenes con prefijo minoru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La entrega consiste en dos archivos con el código, resultados y respuestas a los ejercicios:\n",
    "  1. Un \"notebook\" de Jupyter con los resultados. Las respuestas a los ejercicios debes introducirlas en tantas celdas de código o texto como creas necesarias, insertadas inmediatamente después de  un enuciado y antes del siguiente.\n",
    "  2. Un documento \"pdf\" generado a partir del fuente de Jupyter, por ejemplo usando el comando ``jupyter nbconvert --execute --to pdf notebook.ipynb``, o simplemente imprimiendo el \"notebook\" desde el navegador en la opción del menú \"File->Print preview\". Asegúrate de que el documento \"pdf\" contiene todos los resultados correctamente ejecutados.\n",
    "* Esta práctica puede realizarse en parejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los problemas de visión estéreo se supondrá la existencia de un par de cámaras calibradas cuyas matrices de proyección $\\mathbf{P}_i$ vienen dadas\n",
    "por $$\\mathbf{P}_1 = \\mathbf{K}_1\\cdot\\begin{bmatrix}\\mathbf{I} & \\mathbf{0}\\end{bmatrix}\\cdot\n",
    "    \\begin{bmatrix}\n",
    "        \\mathbf{R}_1 & \\mathbf{t}_1\\\\ \\mathbf{0}^T & 1\n",
    "    \\end{bmatrix},$$ $$\\mathbf{P}_2 = \\mathbf{K}_2\\cdot\\begin{bmatrix}\\mathbf{I} & \\mathbf{0}\\end{bmatrix}\\cdot\n",
    "    \\begin{bmatrix}\n",
    "        \\mathbf{R}_2 & \\mathbf{t}_2\\\\ \\mathbf{0}^T & 1\n",
    "    \\end{bmatrix}.$$\n",
    "    \n",
    "En esta práctica se usarán las matrices de proyección de\n",
    "dos cámaras para determinar la posición tridimensional\n",
    "de puntos de una escena. Esto es posible siempre que se\n",
    "conozcan las proyecciones de cada punto en ambas cámaras. Desafortunadamente, esta información no suele estar\n",
    "disponible y para obtenerla es preciso emplear el contenido\n",
    "de las imágenes (sus píxeles) en un proceso de búsqueda\n",
    "conocido como puesta en correspondencia. Conocer las matrices de proyección de las cámaras permite acotar el área\n",
    "de búsqueda gracias a las restricciones que proporciona la\n",
    "geometría epipolar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T13:58:36.283319Z",
     "start_time": "2020-11-23T13:58:36.045727Z"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment to show results in a window\n",
    "%matplotlib tk\n",
    "import numpy as np\n",
    "import scipy.misc as scpm\n",
    "import scipy.ndimage as scnd\n",
    "import matplotlib.pyplot as ppl\n",
    "import numpy.linalg as npla\n",
    "import maxflow.fastmin\n",
    "import cv2\n",
    "import misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reconstrucción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo un conjunto de correspondencias entre dos\n",
    "imágenes, con matrices de calibración $P_i$ conocidas, es\n",
    "posible llevar a cabo una reconstrucción tridimensional de\n",
    "dichos puntos. En el fichero ``cameras.npz`` se encuentran\n",
    "las matrices de proyección para las dos cámaras. Para cargar\n",
    "este fichero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T13:58:43.985Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n[[-1.59319023e+02  4.10068927e+02 -8.61429776e+01  5.96021124e+04]\n [ 9.56736123e+01 -6.85256589e+00 -4.31511155e+02  2.98592912e+04]\n [-8.69896273e-01 -7.51069223e-02 -4.87482742e-01  5.44164509e+02]]\n[[-1.49296958e+02  4.20482251e+02 -8.03699899e+01  2.66669558e+04]\n [ 9.61686671e+01 -2.92284678e+00 -4.41950717e+02  3.12991880e+04]\n [-8.64354364e-01 -5.83462724e-02 -4.99486983e-01  5.42414607e+02]]\n"
     ]
    }
   ],
   "source": [
    "with np.load(\"cameras.npz\") as cameras:\n",
    "    print(1)\n",
    "    P1 = cameras[\"left\"]\n",
    "    print(P1)\n",
    "    P2 = cameras[\"right\"]\n",
    "    print(P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las imágenes con el prefijo minoru comparten este par de matrices de proyección.\n",
    "\n",
    "Leemos las imágenes y marcammos al menos seis puntos correspondientes en cada una de ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T13:59:24.314591Z",
     "start_time": "2020-11-23T13:59:24.310Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9027a64997d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m P1 = [[-1.59319023e+02,  4.10068927e+02, -8.61429776e+01,  5.96021124e+04]\n\u001b[1;32m----> 2\u001b[1;33m  \u001b[1;33m[\u001b[0m \u001b[1;36m9.56736123e+01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m6.85256589e+00\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m4.31511155e+02\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m2.98592912e+04\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m  [-8.69896273e-01, -7.51069223e-02, -4.87482742e-01,  5.44164509e+02]]\n\u001b[0;32m      4\u001b[0m P2 = [[-1.49296958e+02,  4.20482251e+02, -8.03699899e+01,  2.66669558e+04]\n\u001b[0;32m      5\u001b[0m  \u001b[1;33m[\u001b[0m \u001b[1;36m9.61686671e+01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2.92284678e+00\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m4.41950717e+02\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m3.12991880e+04\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "P1 = [[-1.59319023e+02,  4.10068927e+02, -8.61429776e+01,  5.96021124e+04]\n",
    " [ 9.56736123e+01, -6.85256589e+00, -4.31511155e+02,  2.98592912e+04]\n",
    " [-8.69896273e-01, -7.51069223e-02, -4.87482742e-01,  5.44164509e+02]]\n",
    "P2 = [[-1.49296958e+02,  4.20482251e+02, -8.03699899e+01,  2.66669558e+04]\n",
    " [ 9.61686671e+01, -2.92284678e+00, -4.41950717e+02,  3.12991880e+04]\n",
    " [-8.64354364e-01, -5.83462724e-02, -4.99486983e-01,  5.42414607e+02]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T13:59:25.471537Z",
     "start_time": "2020-11-23T13:59:25.461Z"
    }
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"images/minoru_cube3_left.jpg\")\n",
    "img2 = cv2.imread(\"images/minoru_cube3_right.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T13:59:26.034547Z",
     "start_time": "2020-11-23T13:59:26.029Z"
    }
   },
   "outputs": [],
   "source": [
    "pt1, pt2 = misc.askpoints(img1,img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T13:59:28.344616Z",
     "start_time": "2020-11-23T13:59:28.342Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[105.9516129 , 206.37096774, 304.30645161, 286.56451613,\n",
       "        202.46774194, 115.53225806],\n",
       "       [ 22.10919355,  56.8833871 ,  24.94790323, 149.49629032,\n",
       "        202.72209677, 145.59306452],\n",
       "       [  1.        ,   1.        ,   1.        ,   1.        ,\n",
       "          1.        ,   1.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "pt1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 1.** Implementa la función ``M = reconstruct(points1, points2, P1, P2)``\n",
    "que, dados una serie de N puntos 2D ``points1`` de la primera imagen y sus \n",
    "N homólogos ``points2`` de la segunda imagen\n",
    "(ambos en coordenadas homogéneas, 3 x N), y el par de matrices\n",
    "de proyección P1 y P2 de la primera y la segunda cámara\n",
    "respectivamente, calcule la reconstrucción tridimensional\n",
    "de cada punto. De ese modo, si ``points1`` y\n",
    "``points2`` son 3 × N , la matriz resultante M debe ser 4 × N.\n",
    "\n",
    "El tipo de reconstrucción debe ser algebraico, no geométrico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T11:30:55.167532Z",
     "start_time": "2020-11-23T11:30:55.160534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Función que dada las matrices de proyección y un mismo punto en dos imágenes devuelve el punto en la escena en coordeandas homogéneas\n",
    "def triangular_punto(P1, P2, pt1, pt2):\n",
    "    A = np.zeros(shape=(4,3))\n",
    "    b = np.zeros(shape=(4,1))\n",
    "    # Creamos la matriz A\n",
    "    # Puntos de la imagen I\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            A[i][j] = P1[i][j] - P1[2][j] * (pt1[0] if i == 0 else pt1[1])#np.power(new_pt1[0][0], i % 2) * np.power(new_pt1[0][1], (i + 1) % 2)\n",
    "    # Puntos de la imagen I'\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            A[i+2][j] = P2[i][j] - P2[2][j] * (pt2[0] if i == 0 else pt2[1])#np.power(new_pt2[0][0], i % 2) * np.power(new_pt2[0][1], (i + 1) % 2)\n",
    "    # Creamos el vector b\n",
    "    # Para la imagen I\n",
    "    for i in range(2):\n",
    "        j = 3\n",
    "        b[i][0] = - (P1[i][j] - P1[2][j] * (pt1[0] if i == 0 else pt1[1]) )#np.power(new_pt1[0][0], i % 2) * np.power(new_pt1[0][1], (i + 1) % 2))\n",
    "    # Para la imagen I'\n",
    "    for i in range(2):\n",
    "        j = 3\n",
    "        b[i+2][0] = - (P2[i][j] - P2[2][j] * (pt2[0] if i == 0 else pt2[1]) )#np.power(new_pt2[0][0], i % 2) * np.power(new_pt2[0][1], (i + 1) % 2))\n",
    "\n",
    "    # Resolvemos el sistema\n",
    "    x, residuals, rank, s = np.linalg.lstsq(A,b)\n",
    "    \n",
    "    return np.append(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T11:31:16.077601Z",
     "start_time": "2020-11-23T11:31:16.067Z"
    }
   },
   "outputs": [],
   "source": [
    "def reconstruct(points1, points2, P1, P2):\n",
    "    \"\"\"Reconstruct a set of points projected on two images.\"\"\"\n",
    "    # Convertimos a coordenadas cartesianas\n",
    "    new_pt1 =  [[pt1[0][i], pt1[1][i]]/ pt1[2][i] for i in range(len(pt1[0]))] #points1[0:2,:]/points1[2,:]\n",
    "    new_pt2 =  [[pt2[0][i], pt2[1][i]]/ pt2[2][i] for i in range(len(pt2[0]))] #points2[0:2,:]/points2[2,:]\n",
    "    \n",
    "    ret = np.zeros(shape=(4, len(points1[0])))\n",
    "    # Hallamos el punto en la escena para cada punto en la imagen\n",
    "    for i in range(len(new_pt1)):\n",
    "        ret[:,i] = triangular_punto(P1, P2, new_pt1[i], new_pt2[i])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar que la función está biem implementada, se recalculan los puntos de la imágen utilizando P1 y P2 y se comparan con los marcados previamente. Podemos ver como hay pequeñas diferencias, que puede ser debido a un error mínimo introducido al calcular manualmente las correspondencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T11:31:17.524592Z",
     "start_time": "2020-11-23T11:31:17.523Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calculated pt1: [[106.08166341  24.18510719   1.        ]]\npt1 real: [105.9516129   22.10919355   1.        ]\ncalculated pt2: [[ 6.42221303 26.45624592  1.        ]]\npt2 real: [ 6.53225806 28.49629032  1.        ]\ncalculated pt1: [[206.37072458  56.86337671   1.        ]]\npt1 real: [206.37096774  56.8833871    1.        ]\ncalculated pt2: [[83.53235103 60.80618956  1.        ]]\npt2 real: [83.53225806 60.7866129   1.        ]\ncalculated pt1: [[304.3043871   24.51056346   1.        ]]\npt1 real: [304.30645161  24.94790323   1.        ]\ncalculated pt2: [[204.53056531  28.56782288   1.        ]]\npt2 real: [204.53225806  28.14145161   1.        ]\ncalculated pt1: [[286.5676571  149.73454042   1.        ]]\npt1 real: [286.56451613 149.49629032   1.        ]\ncalculated pt2: [[198.49780053 155.29603317   1.        ]]\npt2 real: [198.5        155.52854839   1.        ]\ncalculated pt1: [[202.47334867 203.14962538   1.        ]]\npt1 real: [202.46774194 202.72209677   1.        ]\ncalculated pt2: [[ 97.01134791 209.04555182   1.        ]]\npt2 real: [ 97.01612903 209.46403226   1.        ]\ncalculated pt1: [[115.54005323 146.01491864   1.        ]]\npt1 real: [115.53225806 145.59306452   1.        ]\ncalculated pt2: [[ 26.39721286 150.85601628   1.        ]]\npt2 real: [ 26.40322581 151.27048387   1.        ]\n"
     ]
    }
   ],
   "source": [
    "points3d = reconstruct(pt1, pt2, P1, P2)\n",
    "\n",
    "for i in range(len(points3d[0])):\n",
    "    x = points3d[:, i].reshape((4,1))\n",
    "    calculated_pt1 = np.dot(P1, x)\n",
    "    calculated_pt2 = np.dot(P2, x)\n",
    "    for j in range(len(calculated_pt1)):\n",
    "        calculated_pt1[j][0] /= calculated_pt1[2][0]\n",
    "        calculated_pt2[j][0] /= calculated_pt2[2][0]\n",
    "\n",
    "    print(f\"calculated pt1: {calculated_pt1.reshape(1,3)}\")\n",
    "    print(f\"pt1 real: {pt1[:,i]}\")\n",
    "    print(f\"calculated pt2: {calculated_pt2.reshape(1,3)}\")\n",
    "    print(f\"pt2 real: {pt2[:, i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruye los puntos marcados y pinta su estructura 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.axes3d.Axes3D at 0x28301f14388>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# reconstruct\n",
    "mM=reconstruct(pt1, pt2, P1, P2)\n",
    "\n",
    "# convert from homog to cartesian\n",
    "mM = mM[0:3,:] / mM[3,:]\n",
    "# plot 3D\n",
    "misc.plot3D(mM[0,:],mM[1,:],mM[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2.**  Elige un par estéreo de las imágenes del conjunto \"building\" de la práctica de calibración y realiza una reconstrucción de un conjunto de puntos de dicho edificio estableciendo las correspondencias a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3.**  Reproyecta los resultados de la reconstrucción\n",
    "en las dos cámaras y dibuja las proyecciones sobre las\n",
    "imágenes originales. Pinta también en otro color los puntos seleccionados manualmente. Comprueba si las proyecciones coinciden con los puntos marcados a mano. Comenta los resultados.\n",
    "Para dibujar los puntos puedes usar la función plothom\n",
    "de la práctica anterior o la versión que se distribuye con esta\n",
    "práctica (misc.plothom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proyecto los puntos en ambas cámaras\n",
    "proy1 = P1.dot(points3d)\n",
    "proy2 = P2.dot(points3d)\n",
    "\n",
    "# Pinto con misc.plothom()\n",
    "ppl.figure()\n",
    "misc.plothom(pt1,'bx')\n",
    "misc.plothom(proy1,'r.')\n",
    "ppl.imshow(img1)\n",
    "ppl.show()\n",
    "\n",
    "ppl.figure()\n",
    "misc.plothom(pt2,'bx')\n",
    "misc.plothom(proy2,'r.')\n",
    "ppl.imshow(img2)\n",
    "ppl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geometría epipolar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La geometría epipolar deriva de las relaciones que aparecen en las proyecciones de una escena sobre un par de\n",
    "cámaras. La matriz fundamental $\\mathbf{F}$, que depende exclusivamente de la configuración de las cámaras y no de la escena\n",
    "que éstas observan, es la representación algebráica de dicha\n",
    "geometría: a partir de ella se pueden calcular los epipolos\n",
    "y las líneas epipolares. La relación entre un par de cámaras\n",
    "$\\mathbf{P}_1$, $\\mathbf{P}_2$ y la matriz fundamental es de n -a- 1 (salvo factor de\n",
    "escala). Es decir, dadas dos cámaras calibradas, sólo tienen\n",
    "una matriz fundamental (excepto un factor de escala); dada\n",
    "una matriz fundamental existen infinitas configuraciones de\n",
    "cámaras posibles asociadas a ella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Estimación de la matriz fundamental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 4.** Implementa la función ``F = projmat2f(P1, P2)``\n",
    "que, dadas dos matrices de proyección, calcule la matriz\n",
    "fundamental asociada a las mismas. $\\mathbf{F}$ debe ser tal que,\n",
    "si $m_1$ de la imagen 1 y $m_2$ de la imagen 2 están en\n",
    "correspondencia, entonces $m_2^\\top F m_1 = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz fundamental F viene dada por la siguiente fórmula:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projmat2f(P1,P2): \n",
    "    \"\"\" Calcula la matriz fundamental a partir de dos de proyeccion\"\"\"\n",
    "    # Descomponemos las matrices de proyección en A,B, b y d\n",
    "    A = P1[:, 0:3]\n",
    "    B = P2[:, 0:3]\n",
    "    b = P1[:, 3]\n",
    "    d = P2[:, 3]\n",
    "\n",
    "    A_ = np.linalg.inv(A)\n",
    "    B_ = np.linalg.inv(B)\n",
    "\n",
    "    B_aux = np.dot(B_,d)\n",
    "    A_aux = np.dot(A_,b)\n",
    "    aux = B_aux - A_aux\n",
    "    # Convertimos aux con la transformación vista en clase\n",
    "    aux = np.array([[0, -aux[2], aux[1]], [aux[2], 0, -aux[0]], [-aux[1], aux[0], 0]])\n",
    "    F = np.dot(np.dot(B_.T, aux), A_)\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 8.37918051e-09 -2.64352488e-06  8.61307712e-04]\n [ 8.17120601e-06  4.36740640e-06  1.37641120e-01]\n [-2.27541839e-03 -1.42176580e-01  7.61491838e-03]]\n"
     ]
    }
   ],
   "source": [
    "# compute Fundamental matrix\n",
    "F = projmat2f(P1, P2)\n",
    "# Comprobamos la mtriz\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 5** ¿Cómo es la matriz fundamental de dos cámaras\n",
    "que comparten el mismo centro? (Por ejemplo, dos cámaras\n",
    "que se diferencian sólo por una rotación.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Comprobación de F (OPCIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los siguientes dos ejercicios vamos a comprobar que la matriz F estimada a partir de P1 y P2 es correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 6.** Comprueba que F es la matriz fundamental asociada a las cámaras ``P1`` y ``P2``. Para ello puedes utilizar el resultado 9.12, que aparece en la página 255 del libro Hartley, Zisserman. \"Multipe View Geometry in Computer Vision.\" (sedond edition). Cambridge University Press, 2003."
   ]
  },
  {
   "source": [
    "A non-zero matrix F is the fundamental matrix corresponding to a pair of camera matrices P and P' if and only if P'_TFP is skew-symmetric.\n",
    "\n",
    "Si una matrix es antisimétrica, por definición:\n",
    "A + A_T = 0\n",
    "\n",
    "Entonces comprobaremos que se cumple esa propiedad."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-5.84991546e-15 -3.99680289e-15 -1.42108547e-14  5.45696821e-12]\n [-3.99680289e-15  1.03939998e-15  5.95079541e-14 -8.92441676e-12]\n [-1.42108547e-14  5.95079541e-14 -1.99374250e-14  0.00000000e+00]\n [ 5.45696821e-12 -8.92441676e-12  0.00000000e+00 -8.46305775e-10]]\n"
     ]
    }
   ],
   "source": [
    "producto = np.dot(np.dot(P2.T,F), P1)\n",
    "\n",
    "# Si es la matrix fundamnetal, la suma del producto y su transpuesta debería ser 0\n",
    "print(producto + producto.T)\n",
    "# En este caso vemos que no sale 0 literal, pero puede ser por errores de cálculo de los tipos, aún así vemos que algunos son 0 y otros son valores muy muy pequeños cercanos a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede comprobar geométricamente la bondad de una matriz F, si  las epipolares con ella estimadas pasan por el homólogo de un punto dado en una de las imágenes.\n",
    "\n",
    "Dada la matriz fundamental $\\mathbf{F}$ entre las cámaras 1 y 2,\n",
    "se puede determinar, para un determinado punto $m_1$ en la\n",
    "imagen de la cámara 1, cuál es la recta epipolar $l_2$ donde se\n",
    "encontrará su homólogo en la cámara 2: $$l_2 = \\mathbf{F} m_1.$$\n",
    "\n",
    "Las siguientes dos funciones sirven para comprobar esta\n",
    "propiedad. En primer lugar, se necesita una función que\n",
    "dibuje rectas expresadas en coordenadas homogéneas, es\n",
    "decir, la versión de plothom para rectas en lugar de puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 7.** Implementa la función ``plothline(line)``\n",
    "que, dada una línea expresada en coordenadas homogéneas,\n",
    "la dibuje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plothline(line, axes = None):\n",
    "    \"\"\"Plot a line given its homogeneous coordinates.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    line : array_like\n",
    "        Homogeneous coordinates of the line.\n",
    "    axes : AxesSubplot\n",
    "        Axes where the line should be plotted. If not given,\n",
    "        line will be plotted in the active axis.\n",
    "    \"\"\"\n",
    "    if axes == None:\n",
    "        axes = ppl.gca()\n",
    "    \n",
    "    [x0, x1, y0, y1] = axes.axis()\n",
    "\n",
    "    #     (x0, y0) ._____________________. (x1, y0)\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #     (x0, y1) .---------------------. (x1, y1)\n",
    " \n",
    "    # TODO: Compute the intersection of the line with the image\n",
    "    # borders.\n",
    "\n",
    "        \n",
    "    # TODO: Plot the line with axes.plot.\n",
    "    #axes.plot(...)\n",
    "    plotline = axes.plot(... , 'r-')\n",
    "    \n",
    "    axes.axis([x0, x1, y0, y1])\n",
    "    return plotline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 8.** Completa la función ``plot_epipolar_lines(image1, image2, F)``\n",
    "que, dadas dos imágenes y la matriz fundamental que\n",
    "las relaciona, pide al usuario puntos en la imagen 1 y\n",
    "dibuje sus correspondientes epipolares en la imagen 2 usando ``plothline``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epipolar_lines(image1, image2, F):\n",
    "    \"\"\"Ask for points in one image and draw the epipolar lines for those points.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image1 : array_like\n",
    "        First image.\n",
    "    image2 : array_like\n",
    "        Second image.\n",
    "    F : array_like\n",
    "        3x3 fundamental matrix from image1 to image2.\n",
    "    \"\"\"\n",
    "    # Prepare the two images.\n",
    "    fig = ppl.gcf()\n",
    "    fig.clf()\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(image1)\n",
    "    ax1.axis('image')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(image2)\n",
    "    ax2.axis('image')\n",
    "    ppl.draw()\n",
    "    \n",
    "    ax1.set_xlabel(\"Choose points in left image (or right click to end)\")\n",
    "    point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    while len(point) != 0:\n",
    "        # point has the coordinates of the selected point in the first image.\n",
    "        point = np.hstack([np.array(point[0]), 1])\n",
    "        ax1.plot(point[0], point[1], '.r')\n",
    "        \n",
    "        # TODO: Determine the epipolar line.\n",
    "        # Por definición la linea epipolar es la multiplicación de F por el punto\n",
    "        line = np.dot(F, point)\n",
    "        \n",
    "        # Plot the epipolar line with plothline (the parameter 'axes' should be ax2).\n",
    "        plothline(line, axes=ax2)\n",
    "        \n",
    "        ppl.draw()\n",
    "        # Ask for a new point.\n",
    "        point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    \n",
    "    ax1.set_xlabel('')\n",
    "    ppl.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza esta función con un par de imágenes llamándola\n",
    "de dos formas diferentes: seleccionando puntos en la imagen\n",
    "izquierda y dibujando las epipolares en la imagen derecha\n",
    "y viceversa. Comprueba en ambos casos que las epipolares\n",
    "siempre pasan por el punto de la segunda imagen correspondiente al seleccionado en la primera. Esto confirmara la corrección de la matriz F.\n",
    "\n",
    "Añade dos figuras una que muestre la selección de puntos en\n",
    "la imagen izquierda y las rectas correspondientes en la\n",
    "imagen derecha, y otra que lo haga al revés. Indica para\n",
    "ambos casos qué matriz fundamental has usado al llamar a\n",
    "``plot_epipolar_lines``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plothline' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-a02df6ec0f26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_epipolar_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-e99052425d20>\u001b[0m in \u001b[0;36mplot_epipolar_lines\u001b[1;34m(image1, image2, F)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# Plot the epipolar line with plothline (the parameter 'axes' should be ax2).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mplothline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mppl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plothline' is not defined"
     ]
    }
   ],
   "source": [
    "plot_epipolar_lines(img1, img2, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epipolar_lines(img2, img1, np.transpose(F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Rectificación de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es recomendable trabajar a partir de ahora con imágenes\n",
    "en blanco y negro y con valores reales entre 0 y 1 para cada\n",
    "uno de sus píxeles. Eso se puede conseguir con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = misc.rgb2gray(img1/255.0)\n",
    "img2 = misc.rgb2gray(img2/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoría de algoritmos de puesta en correspondencia,\n",
    "incluyendo el que se va a implementar en esta práctica,\n",
    "requieren que las imágenes de entrada estén rectificadas.\n",
    "\n",
    "Dos imágenes están rectificadas si sus correspondientes epipolares están alineadas horizontalmente. La rectificación de\n",
    "imágenes facilita enormemente los algoritmos de puesta en\n",
    "correspondencia, que pasan de ser problemas de búsqueda\n",
    "bidimensional a problemas de búsqueda unidimensional\n",
    "sobre filas de píxeles de las imágenes. En el material de\n",
    "la práctica se han incluido dos funciones que rectifican\n",
    "(mediante un método lineal) dos imágenes. La función\n",
    "``H1, H2 = misc.projmat2rectify(P1, P2, imsize)``\n",
    "devuelve, dadas las dos matrices de proyección y el tamaño de las imágenes en formato (filas,columnas), las\n",
    "homografías que rectifican, respectivamente, la imagen 1\n",
    "y la imagen 2. La función ``projmat2rectify`` hace uso\n",
    "de ``projmat2f``, por lo que\n",
    "es necesario que esta función esté disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 9.** Se tienen dos imágenes no rectificadas ``im1`` e\n",
    "``im2``, y su matriz fundamental asociada $\\mathbf{F}$ . Con el procedimiento explicado, se encuentran un par de homografías $\\mathbf{H}_1$ y $\\mathbf{H}_2$ que dan lugar a las imágenes rectificadas ``O1`` y ``O2``. ¿Cuál es la matriz fundamental $\\mathbf{F}′$ asociada a estas dos imágenes? ¿Por qué?\n",
    "\n",
    "Nota: F ′ depende exclusivamente de F , H1 y H2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 10.** Rectifica el par de imágenes estéreo ``img1`` e ``img2`` y calcula\n",
    "la matriz fundamental asociada a estas imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1, H2 = misc.projmat2rectify(... TODO ...)\n",
    "O1, O2 = misc.rectify_images( ... TODO ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.imshow(O1)\n",
    "ppl.figure()\n",
    "ppl.imshow(O2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 11.** Calcula y muestra la matriz fundamental de las imágenes\n",
    "rectificadas. Justifica el resultado obtenido (mira la sección 9.3.1 del libro de Hartley y Zisserman, pág. 248 y 249)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr=\n",
    "Fr=Fr/Fr[2,1]\n",
    "Fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 12.** Usa ``plot_epipolar_lines`` para dibujar varias líneas epiplares de las imágenes rectificadas. Muestra los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epipolar_lines(... TODO ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Búsqueda de correspondencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda de correspondencias consigue establecer automáticamente las correspondencias de puntos entre dos\n",
    "imágenes (lo que se ha hecho manualmente en el ejercicio 2)\n",
    "haciendo uso de las restricciones que proporciona la geometría epipolar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Cálculo de las medidas de similaridad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez rectificadas las dos imágenes de un par estéreo,\n",
    "se pueden buscar las correspondencias. Una matriz de disparidades $\\mathbf{S}$ indica, para cada píxel de la imagen 1\n",
    "rectificada, a cuántos píxeles de diferencia está su correspondencia\n",
    "en la imagen 2 rectificada. En nuestra práctica, para simplificar el problema, vamos a considerar que los elementos\n",
    "de $\\mathbf{S}$ son enteros. Para el píxel en la posición $(x, y)$ en la\n",
    "imagen 1, su correspondiente está en $(x + S[y, x], y)$ en la\n",
    "imagen 2. Si $S[y, x] < 0$, la correspondencia está hacia la\n",
    "izquierda; si $S[y, x] > 0$, la correspondencia está hacia la\n",
    "derecha; si $S[y, x] = 0$, las coordenadas de los dos puntos\n",
    "coinciden en ambas imágenes.\n",
    "\n",
    "La búsqueda de correspondencias requiere ser capaz de\n",
    "determinar el parecido visual entre píxeles de dos imágenes.\n",
    "Si los píxeles $m_1$ y $m_2$ son visualmente parecidos, tienen\n",
    "más probabilidad de estar en correspondencia que otros\n",
    "que sean visualmente diferentes. Como la\n",
    "apariencia (el nivel de gris) de un único píxel es propensa\n",
    "al ruido y poco discriminativa, el elemento de puesta en\n",
    "correspondencia será una ventana centrada en el píxel.\n",
    "Dado un píxel $m$ de una imagen, llamaremos vecindad\n",
    "del píxel de radio $K$ al conjunto de píxeles de la imagen que se encuentren dentro de una ventana de tamaño\n",
    "$(2K + 1) × (2K + 1)$ píxeles centrada en $m$ . El número de\n",
    "píxeles de una vecindad de radio $K$ es $N = (2K + 1)^2$.\n",
    "Dadas dos vecindades $w_1$ y $w_2$ de dos píxeles, el parecido\n",
    "visual entre ellas puede calcularse con la suma de *diferencias\n",
    "al cuadrado (SSD)* de cada una de sus componentes\n",
    "$$d_{SSD}(\\mathbf{v}, \\mathbf{w}) = \\sum_{i=1}^N(\\mathbf{v}_i - \\mathbf{w}_i)^2.$$\n",
    "\n",
    "La distancia $d_{SSD}$ es siempre positiva, es pequeña cuando\n",
    "dos ventanas son visualmente parecidas y grande en caso\n",
    "contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 13.** Implementa la función\n",
    "``C = localssd(im1, im2, K)``\n",
    "que calcula la suma de diferencias al cuadrado entre las\n",
    "ventanas de radio K de la imagen 1 y la imagen 2. El\n",
    "resultado debe ser una matriz del mismo tamaño que las\n",
    "imágenes de entrada que contenga en cada punto el valor\n",
    "de $d_{SSD}$ para la ventana de la imagen 1 y la ventana\n",
    "de la imagen 2 centradas en él. Es decir, $C[i,j]$ debe\n",
    "ser el resultado de $d_{SSD}$ para las ventanas centradas en\n",
    "$im1[i,j]$ e $im2[i,j]$.\n",
    "\n",
    "Para este ejercicio puede resultar útil la función\n",
    "``scipy.ndimage.convolve``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localssd(im1, im2, K):\n",
    "    \"\"\"\n",
    "    The local sum of squared differences between windows of two images.\n",
    "    \n",
    "    The size of each window is (2K+1)x(2K+1).\n",
    "    \"\"\"\n",
    "    ... TODO ...\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 14.** Implementa la función ``D = ssd_volume(im1, im2, disps, K)`` que calcula la suma de diferencias al cuadrado entre las\n",
    "ventanas de la imagen ``im1`` y la imagen ``im2`` desplazada\n",
    "horizontalmente. El parámetro ``disps`` debe ser una lista\n",
    "de valores indicando las disparidades que se usarán para desplazar la imagen ``im2``. Por ejemplo, si ``disps`` es\n",
    "``np.arange(-3,2)``, se llamará 5 veces a ``localssd`` para la\n",
    "imagen 1 y la imagen 2 desplazada −3 , −2 , −1 , 0 y 1 píxeles\n",
    "en sentido horizontal. K es el parámetro que indica el radio\n",
    "de las ventanas usado por localssd.\n",
    "\n",
    "El valor devuelto D será un array de tamaño $M × N × L$,\n",
    "donde L es el número de disparidades indicadas por ``disps``,\n",
    "``L = len(disps)`` (es decir, el número de veces que se ha\n",
    "llamado a ``localssd``); M y N son, respectivamente, el\n",
    "número de filas y de columnas de las imágenes de entrada.\n",
    "El elemento ``D[y,x,l]`` debe ser la SSD entre la ventana\n",
    "centrada en ``im1[y,x]`` y la ventana centrada en ``im2[y,x + disps[l]]``.\n",
    "\n",
    "``D[y,x,l]`` debe ser muy grande para aquellos valores en\n",
    "los que ``im2[y,x + disps[l]]`` no esté definido, es decir,\n",
    "el índice``(y,x+disps[l])`` se sale de la imagen 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_volume(im1, im2, disps, K):\n",
    "    \"\"\"\n",
    "    Calcula el volumen de disparidades SSD\n",
    "    \"\"\"\n",
    "    \n",
    "    ... TODO ...\n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 15.** El conjunto de disparidades ``disps`` debe ser lo más pequeño posible, para mejorar el rendimiento de la optimización. Determina un procedimiento para estimar manualmente el conjunto de disparidades posibles y aplícalo a las imágenes O1 y O2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disps = np.arange( ..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica la función ``ssd_volume`` al par de imágenes O1 y O2\n",
    "con las disparidades estimadas en el ejercicio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = ssd_volume(O2, O1, disps, 5)\n",
    "\n",
    "# to speed-up the optimization ahead, discard the par of the image showing only background\n",
    "\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Estimación de la disparidad sin regularizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz D calculada en el ejercicio anterior proporciona\n",
    "los costes unitarios $D_i$ de una función de energía sin regularización de la forma $$E(x) = \\sum_{i} D_i(x_i),$$\n",
    "donde $D_i(l)$ viene dado por $D[y,x,l]$, suponiendo que\n",
    "el píxel $i$ tenga coordenadas $(x, y)$. Las variables \n",
    "$x = (x_1 ,\\ldots, x_{NM})$ indican las etiquetas de cada uno de los\n",
    "píxeles. En este caso, las etiquetas son los índices del\n",
    "array ``disps``, que a su vez son las disparidades horizontales.\n",
    "Por eso, a partir de aquí se hablará indistintamente de\n",
    "etiquetas y disparidades. Sólo es necesario recordar que la\n",
    "etiqueta $l$ está asociada a la disparidad ``disps[l]``.\n",
    "\n",
    "\n",
    "Minimizando la energía $x = \\arg\\min_x E(x)$,\n",
    "se obtiene un vector de etiquetas óptimo $x^*$ que indica, para\n",
    "cada píxel, cuál es su disparidad horizontal entre las dos\n",
    "imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 16.** Minimiza $E(x)$ y muestra las disparidades resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ... TODO ...\n",
    "ppl.imshow(res,cmap='gray')\n",
    "ppl.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Estimación de la disparidad regularizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El etiquetado usando exclusivamente términos unitarios\n",
    "es muy sensible al ruido y propenso a que aparezcan zonas\n",
    "de píxeles cercanos con mucha variación en las etiquetas.\n",
    "Esto es especialmente notable en zonas planas (es decir, sin\n",
    "textura) de las imágenes originales, donde no hay suficiente\n",
    "información para establecer una correspondencia basándose\n",
    "exclusivamente en la apariencia visual de ventanas pequeñas. Por eso es necesario incluir un término de suavizado\n",
    "o regularización en la función de energía. Los tipos de\n",
    "saltos de etiquetas que aparecerán en el resultado final\n",
    "dependerán de cómo sea ese término de suavizado.\n",
    "\n",
    "La función de energía que utilizaremos para calcular\n",
    "las disparidades en la práctica será el resultado de añadir\n",
    "a la expresión (6) un término que penalice los cambios de\n",
    "disparidad en los píxeles vecinos: $$E_r(x) = \\sum_{i} D_i(x_i) + \\lambda\\sum_{ij} \\min(k,|x_i-x_j|).$$ Siendo $j$ los índices de los píxeles vecinos del $i$ en la imagen.\n",
    "La solución al problema de la correspondencia vendrá dado\n",
    "por el conjunto de etiquetas (disparidades) de los píxeles de\n",
    "la imagen que minimicen $E_r(x)$.\n",
    "\n",
    "En [Yuri Boykov, Olga Veksler, and Ramin Zabih. \"Fast approximate\n",
    "energy minimization via graph cuts\". *IEEE Transactions on Pattern\n",
    "Analysis and Machine Intelligence*, 23:1222–1239, 2001.] se presentan métodos para resolver algunos problemas de optimización con varias etiquetas empleando\n",
    "algoritmos de cortes de grafos. Es recomendable repasar las\n",
    "secciones 5 y 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 17.** Escribe la función ``find_corresp_aexpansion(D, initLabels, lmb, maxV)``,\n",
    "que recibe un volumen ssd, ``D``, un conjunto inicial de\n",
    "etiquetas, ``initLabels``, que puede ser el obtenido en el\n",
    "ejercicio 5, el valor de la constante $\\lambda$, y el valor máximo\n",
    "de la función de coste $|x_i − x_j|$, que tendrás que establecer empíricamente. El resultado de esta función serán las\n",
    "etiquetas que minimizan $E_r(x)$. Para ello debes utilizar la función ``maxflow.fastmin.aexpansion_grid(D, V, max_cycles=None, labels=None)`` del paquete\n",
    "*PyMaxFlow*, que resuelve el problema anterior mediante un\n",
    "algoritmo de cortes de grafos empleando una $\\alpha$-expansión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corresp_aexpansion(D, initialLabels, lmb, maxV):\n",
    "    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama a esta función y muestra una figura con las etiquetas que resulten de la minimización de la energía para el volumen ssd ``D`` (este proceso puede durar varios minutos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = find_corresp_aexpansion(D, res, ... , ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.imshow(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de etiquetas óptimas X obtenida de la minimización de la función de energía puede transformarse en\n",
    "la matriz de disparidades S indexando en cada una de sus\n",
    "celdas el array de disparidades disps ``S = disps[X]``.\n",
    "Ahora, el píxel de coordenadas (x, y) de la primera imagen\n",
    "rectificada tendrá su correspondencia en el píxel de coordenadas (x + S [y, x], y) de la segunda imagen rectificada.\n",
    "\n",
    "El siguiente ejercicio usa la matriz de disparidades para\n",
    "establecer automáticamente las correspondencias entre un\n",
    "par de imágenes sin rectificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 18.** Implementa la función\n",
    "``plot_correspondences(image1, image2, S, H1,H2)``\n",
    "que, dado un par de imágenes sin rectificar, la matriz de\n",
    "disparidades entre las imágenes rectificadas y las homogra-\n",
    "fías que llevan de las imágenes sin rectificar a las imágenes\n",
    "rectificadas, pida al usuario puntos en la primera imagen y\n",
    "dibuje sus correspondencias en la segunda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correspondences(image1, image2, S, H1, H2):\n",
    "    \"\"\"\n",
    "    Ask for points in the first image and plot their correspondences in\n",
    "    the second image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image1, image2 : array_like\n",
    "        The images (before rectification)\n",
    "    S : array_like\n",
    "        The matrix of disparities.\n",
    "    H1, H2 : array_like\n",
    "        The homographies which rectify both images.\n",
    "    \"\"\"\n",
    "    # Prepare the two images.\n",
    "    fig = ppl.gcf()\n",
    "    fig.clf()\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(image1)\n",
    "    ax1.axis('image')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(image2)\n",
    "    ax2.axis('image')\n",
    "    ppl.draw()\n",
    "    \n",
    "    ax1.set_xlabel(\"Choose points in left image (or right click to end)\")\n",
    "    point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    while len(point) != 0:\n",
    "        # point has the coordinates of the selected point in the first image.\n",
    "        point = np.c_[np.array(point), 1].T\n",
    "        ax1.plot(point[0,:], point[1,:], '.r')\n",
    "        \n",
    "        # TODO: Determine the correspondence of 'point' in the second image.\n",
    "        # perhaps you have to swap the image co-ordinates.\n",
    "        \n",
    "        \n",
    "        # TODO: Plot the correspondence with ax2.plot.\n",
    "        \n",
    "\n",
    "        ax2.plot(... ,... ,'r.')\n",
    "        \n",
    "        ppl.draw()\n",
    "        # Ask for a new point.\n",
    "        point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    \n",
    "    ax1.set_xlabel('')\n",
    "    ppl.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = ... TODO ...\n",
    "plot_correspondences(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}