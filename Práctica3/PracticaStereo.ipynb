{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica de reconstrucción.  Parte II. Visión estéreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visión Computacional <br>\n",
    "Practica 2.\n",
    "\n",
    "**Alumnos:**\n",
    "- César García Cabeza\n",
    "- Enol García Gonzalez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este enunciado está en el archivo \"PracticaStereo.ipynb\" o su versión \"pdf\" que puedes encontrar en el Aula Virtual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetivos de esta práctica son:\n",
    "* reconstruir puntos de una escena a partir de una serie de correspondencias manuales entre dos imágenes calibradas;\n",
    "* determinar la geometría epipolar de un par de cámaras a partir de sus matrices de proyección;\n",
    "* implementar la búsqueda automática de correspondencias que use las restricciones impuestas por la geometría epipolar, aplicando para ello métodos de cortes de grafos;\n",
    "* realizar una reconstrucción densa de la escena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta práctica es necesario disponer del siguiente software:\n",
    "* Python 2.7 ó 3.X \n",
    "* Jupyter http://jupyter.org/.\n",
    "* Las librerías científicas de Python: NumPy, SciPy, y Matplotlib.\n",
    "* La librería OpenCV\n",
    "* La librería PyMaxFlow\n",
    "\n",
    "El material necesario para la práctica se puede descargar del Aula Virtual en la carpeta ``MaterialesPractica`` del tema de visión estéreo. Esta\n",
    "carpeta contiene:\n",
    "* Una serie de pares estéreo en el directorio images;\n",
    "el sufijo del fichero indica si corresponde a la cámara\n",
    "izquierda (_left) o a la derecha (_right). Bajo el\n",
    "directorio ``rectif`` se encuentran varios pares estéreo\n",
    "rectificados.\n",
    "* Un conjunto de funciones auxiliares de ``Python`` en \n",
    "el módulo ``misc.py``. La descripción de las funciones\n",
    "puede consultarse con el comando help o leyendo\n",
    "su código fuente.\n",
    "* El archivo ``cameras.npz`` con las matrices de proyección del par de cámaras con el que se tomaron todas las imágenes con prefijo minoru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La entrega consiste en dos archivos con el código, resultados y respuestas a los ejercicios:\n",
    "  1. Un \"notebook\" de Jupyter con los resultados. Las respuestas a los ejercicios debes introducirlas en tantas celdas de código o texto como creas necesarias, insertadas inmediatamente después de  un enuciado y antes del siguiente.\n",
    "  2. Un documento \"pdf\" generado a partir del fuente de Jupyter, por ejemplo usando el comando ``jupyter nbconvert --execute --to pdf notebook.ipynb``, o simplemente imprimiendo el \"notebook\" desde el navegador en la opción del menú \"File->Print preview\". Asegúrate de que el documento \"pdf\" contiene todos los resultados correctamente ejecutados.\n",
    "* Esta práctica puede realizarse en parejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los problemas de visión estéreo se supondrá la existencia de un par de cámaras calibradas cuyas matrices de proyección $\\mathbf{P}_i$ vienen dadas\n",
    "por $$\\mathbf{P}_1 = \\mathbf{K}_1\\cdot\\begin{bmatrix}\\mathbf{I} & \\mathbf{0}\\end{bmatrix}\\cdot\n",
    "    \\begin{bmatrix}\n",
    "        \\mathbf{R}_1 & \\mathbf{t}_1\\\\ \\mathbf{0}^T & 1\n",
    "    \\end{bmatrix},$$ $$\\mathbf{P}_2 = \\mathbf{K}_2\\cdot\\begin{bmatrix}\\mathbf{I} & \\mathbf{0}\\end{bmatrix}\\cdot\n",
    "    \\begin{bmatrix}\n",
    "        \\mathbf{R}_2 & \\mathbf{t}_2\\\\ \\mathbf{0}^T & 1\n",
    "    \\end{bmatrix}.$$\n",
    "    \n",
    "En esta práctica se usarán las matrices de proyección de\n",
    "dos cámaras para determinar la posición tridimensional\n",
    "de puntos de una escena. Esto es posible siempre que se\n",
    "conozcan las proyecciones de cada punto en ambas cámaras. Desafortunadamente, esta información no suele estar\n",
    "disponible y para obtenerla es preciso emplear el contenido\n",
    "de las imágenes (sus píxeles) en un proceso de búsqueda\n",
    "conocido como puesta en correspondencia. Conocer las matrices de proyección de las cámaras permite acotar el área\n",
    "de búsqueda gracias a las restricciones que proporciona la\n",
    "geometría epipolar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:11:53.609595Z",
     "start_time": "2020-12-04T10:11:53.398595Z"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment to show results in a window\n",
    "%matplotlib tk\n",
    "import numpy as np\n",
    "import scipy.ndimage as scnd\n",
    "import matplotlib.pyplot as ppl\n",
    "import maxflow.fastmin\n",
    "import cv2\n",
    "import misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reconstrucción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo un conjunto de correspondencias entre dos\n",
    "imágenes, con matrices de calibración $P_i$ conocidas, es\n",
    "posible llevar a cabo una reconstrucción tridimensional de\n",
    "dichos puntos. En el fichero ``cameras.npz`` se encuentran\n",
    "las matrices de proyección para las dos cámaras. Para cargar\n",
    "este fichero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-04T10:11:55.925Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-1.59319023e+02  4.10068927e+02 -8.61429776e+01  5.96021124e+04]\n [ 9.56736123e+01 -6.85256589e+00 -4.31511155e+02  2.98592912e+04]\n [-8.69896273e-01 -7.51069223e-02 -4.87482742e-01  5.44164509e+02]]\n[[-1.49296958e+02  4.20482251e+02 -8.03699899e+01  2.66669558e+04]\n [ 9.61686671e+01 -2.92284678e+00 -4.41950717e+02  3.12991880e+04]\n [-8.64354364e-01 -5.83462724e-02 -4.99486983e-01  5.42414607e+02]]\n"
     ]
    }
   ],
   "source": [
    "# CUIDADO\n",
    "# Cargamos las dos matrices de proyección\n",
    "with np.load(\"cameras.npz\") as cameras:\n",
    "    P1 = cameras[\"left\"]\n",
    "    print(P1)\n",
    "    P2 = cameras[\"right\"]\n",
    "    print(P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXPLICACIÓN**\n",
    "Tuvimos muchos problemas con la celda de arriba, cargando a veces las matrices de proyección y otras veces se quedaba colgado y no funcionaba.\n",
    "Optamos por guardar las matrices de proyección en los dos numpy arrays de abajo una vez que la celda de arriba nos funcionó, para así evitarnos problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:12:13.021017Z",
     "start_time": "2020-12-04T10:12:13.018027Z"
    }
   },
   "outputs": [],
   "source": [
    "P1 = np.array([[-1.59319023e02,  4.10068927e02, -8.61429776e01,  5.96021124e04],\n",
    " [ 9.56736123e01, -6.85256589e00, -4.31511155e02,  2.98592912e04],\n",
    " [-8.69896273e-01, -7.51069223e-02, -4.87482742e-01,  5.44164509e02]])\n",
    "P2 = np.array([[-1.49296958e02,  4.20482251e02, -8.03699899e01,  2.66669558e+04],\n",
    " [ 9.61686671e01, -2.92284678e00, -4.41950717e02,  3.12991880e04],\n",
    " [-8.64354364e-01, -5.83462724e-02, -4.99486983e-01,  5.42414607e02]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las imágenes con el prefijo minoru comparten este par de matrices de proyección.\n",
    "\n",
    "Leemos las imágenes y marcamos al menos seis puntos correspondientes en cada una de ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:12:16.746350Z",
     "start_time": "2020-12-04T10:12:16.724350Z"
    }
   },
   "outputs": [],
   "source": [
    "# Leemos las dos imágenes\n",
    "img1 = cv2.imread(\"images/minoru_cube3_left.jpg\")\n",
    "img2 = cv2.imread(\"images/minoru_cube3_right.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:12:49.363446Z",
     "start_time": "2020-12-04T10:12:17.020506Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pedimos al ususario por puntos correspondientes en ambas imágenes\n",
    "pt1, pt2 = misc.askpoints(img1,img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 1.** Implementa la función ``M = reconstruct(points1, points2, P1, P2)``\n",
    "que, dados una serie de N puntos 2D ``points1`` de la primera imagen y sus \n",
    "N homólogos ``points2`` de la segunda imagen\n",
    "(ambos en coordenadas homogéneas, 3 x N), y el par de matrices\n",
    "de proyección P1 y P2 de la primera y la segunda cámara\n",
    "respectivamente, calcule la reconstrucción tridimensional\n",
    "de cada punto. De ese modo, si ``points1`` y\n",
    "``points2`` son 3 × N , la matriz resultante M debe ser 4 × N.\n",
    "\n",
    "El tipo de reconstrucción debe ser algebraico, no geométrico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver este ejercicio algebraicamente, debemos construir el siguiente sistema:\n",
    "\\begin{equation}\n",
    "a_{11}X + a_{12}Y + a_{13}Z = - a_{14}\\\\\n",
    "a_{21}X + a_{22}Y + a_{23}Z = - a_{24}\\\\\n",
    "a'_{11}X + a'_{12}Y + a'_{13}Z = - a'_{14}\\\\\n",
    "a'_{21}X + a'_{22}Y + a'_{23}Z = - a'_{24}\n",
    "\\end{equation}\n",
    "\n",
    "Las 4 ecuaciones de arriba corresponen al mismo punto, pero en dos escenas diferentes (dos ecuaciones primeras imagen 1 y las otras dos a la imagen 2).\n",
    "\n",
    "La parte izquierda del igual, es lo que abajo construímos como A y la parte derecha como b.\n",
    "\n",
    "Para calcular cada a, utilizaremos la sustitución vista en clase con la matriz de proyección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:12:53.048112Z",
     "start_time": "2020-12-04T10:12:53.042114Z"
    }
   },
   "outputs": [],
   "source": [
    "# Función que dada las matrices de proyección y un mismo punto en dos imágenes devuelve el punto en la escena en coordeandas homogéneas\n",
    "def triangular_punto(P1, P2, pt1, pt2):\n",
    "    A = np.zeros(shape=(4,3))\n",
    "    b = np.zeros(shape=(4,1))\n",
    "    # Creamos la matriz A\n",
    "    # Puntos de la imagen I\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            A[i][j] = P1[i][j] - P1[2][j] * (pt1[0] if i == 0 else pt1[1])#np.power(new_pt1[0][0], i % 2) * np.power(new_pt1[0][1], (i + 1) % 2)\n",
    "    # Puntos de la imagen I'\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            A[i+2][j] = P2[i][j] - P2[2][j] * (pt2[0] if i == 0 else pt2[1])#np.power(new_pt2[0][0], i % 2) * np.power(new_pt2[0][1], (i + 1) % 2)\n",
    "    # Creamos el vector b\n",
    "    # Para la imagen I\n",
    "    for i in range(2):\n",
    "        j = 3\n",
    "        b[i][0] = - (P1[i][j] - P1[2][j] * (pt1[0] if i == 0 else pt1[1]) )#np.power(new_pt1[0][0], i % 2) * np.power(new_pt1[0][1], (i + 1) % 2))\n",
    "    # Para la imagen I'\n",
    "    for i in range(2):\n",
    "        j = 3\n",
    "        b[i+2][0] = - (P2[i][j] - P2[2][j] * (pt2[0] if i == 0 else pt2[1]) )#np.power(new_pt2[0][0], i % 2) * np.power(new_pt2[0][1], (i + 1) % 2))\n",
    "\n",
    "    # Resolvemos el sistema\n",
    "    x, residuals, rank, s = np.linalg.lstsq(A,b)\n",
    "    \n",
    "    return np.append(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:12:53.744963Z",
     "start_time": "2020-12-04T10:12:53.739965Z"
    }
   },
   "outputs": [],
   "source": [
    "def reconstruct(points1, points2, P1, P2):\n",
    "    \"\"\"Reconstruct a set of points projected on two images.\"\"\"\n",
    "    # Convertimos a coordenadas cartesianas\n",
    "    new_pt1 =  [[points1[0][i], points1[1][i]]/ points1[2][i] for i in range(len(points1[0]))] \n",
    "    new_pt2 =  [[points2[0][i], points2[1][i]]/ points2[2][i] for i in range(len(points2[0]))]\n",
    "    \n",
    "    ret = np.zeros(shape=(4, len(points1[0])))\n",
    "    # Hallamos el punto en la escena para cada punto en la imagen\n",
    "    for i in range(len(new_pt1)):\n",
    "        ret[:,i] = triangular_punto(P1, P2, new_pt1[i], new_pt2[i])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar que la función está biem implementada, se recalculan los puntos de la imágen utilizando P1 y P2 a partir de los de la escena calculados y se comparan con los marcados previamente. Podemos ver como hay pequeñas diferencias, que puede ser debido a un error mínimo introducido al calcular manualmente las correspondencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:12:56.709793Z",
     "start_time": "2020-12-04T10:12:56.691793Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calculated pt1: [[202.47795391 203.27997702   1.        ]]\npt1 real: [202.46774194 202.67419355   1.        ]\ncalculated pt2: [[ 96.65229622 209.17799899   1.        ]]\npt2 real: [ 96.66129032 209.77096774   1.        ]\ncalculated pt1: [[208.20900857  58.05649933   1.        ]]\npt1 real: [208.14516129  56.48064516   1.        ]\ncalculated pt2: [[85.2551956  62.03564047  1.        ]]\npt2 real: [85.30645161 63.57741935  1.        ]\ncalculated pt1: [[300.42455744  25.3637806    1.        ]]\npt1 real: [300.40322581  26.67419355   1.        ]\ncalculated pt2: [[205.91952208  29.37120638   1.        ]]\npt2 real: [205.9516129   28.09354839   1.        ]\ncalculated pt1: [[289.05461812 149.48871368   1.        ]]\npt1 real: [289.0483871  150.15806452   1.        ]\ncalculated pt2: [[197.42690725 155.06915043   1.        ]]\npt2 real: [197.43548387 154.41612903   1.        ]\ncalculated pt1: [[116.08121637 145.63300139   1.        ]]\npt1 real: [115.88709677 143.06129032   1.        ]\ncalculated pt2: [[ 26.93262065 150.4698369    1.        ]]\npt2 real: [ 27.11290323 152.99677419   1.        ]\ncalculated pt1: [[107.40760354  24.82202137   1.        ]]\npt1 real: [107.37096774  23.83548387   1.        ]\ncalculated pt2: [[ 7.21436373 27.12415851  1.        ]]\npt2 real: [ 7.24193548 28.09354839  1.        ]\n"
     ]
    }
   ],
   "source": [
    "points3d = reconstruct(pt1, pt2, P1, P2)\n",
    "\n",
    "for i in range(len(points3d[0])):\n",
    "    x = points3d[:, i].reshape((4,1))\n",
    "    # Recalculamos los puntos en las imágenes\n",
    "    calculated_pt1 = np.dot(P1, x)\n",
    "    calculated_pt2 = np.dot(P2, x)\n",
    "    for j in range(len(calculated_pt1)):\n",
    "        calculated_pt1[j][0] /= calculated_pt1[2][0]\n",
    "        calculated_pt2[j][0] /= calculated_pt2[2][0]\n",
    "\n",
    "    # Mostramos el punto recalculado en ambas escenas junto al original marcado\n",
    "    print(f\"calculated pt1: {calculated_pt1.reshape(1,3)}\")\n",
    "    print(f\"pt1 real: {pt1[:,i]}\")\n",
    "    print(f\"calculated pt2: {calculated_pt2.reshape(1,3)}\")\n",
    "    print(f\"pt2 real: {pt2[:, i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruye los puntos marcados y pinta su estructura 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:12:59.713398Z",
     "start_time": "2020-12-04T10:12:59.632400Z"
    },
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.axes3d.Axes3D at 0x289ae9eb108>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# reconstruct\n",
    "mM=reconstruct(pt1, pt2, P1, P2)\n",
    "\n",
    "# convert from homog to cartesian\n",
    "mM = mM[0:3,:] / mM[3,:]\n",
    "# plot 3D\n",
    "misc.plot3D(mM[0,:],mM[1,:],mM[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2.**  Elige un par estéreo de las imágenes del conjunto \"building\" de la práctica de calibración y realiza una reconstrucción de un conjunto de puntos de dicho edificio estableciendo las correspondencias a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de la práctica anterior\n",
    "vp1 = np.array([5739.80417367, 2581.55471629,1])\n",
    "vp2 = np.array([4855.66315511, 2645.68868765,1])\n",
    "\n",
    "K = np.array([[3.07135761e03, 0.00000000e00, 1.98914933e03],\n",
    " [0.00000000e00, 3.07135761e03, 1.46301851e03],\n",
    " [0.00000000e00, 0.00000000e00, 1.00000000e00]])\n",
    "\n",
    "R1 = np.array([[-0.65754675,  0.75388299, -0.0093219 ],\n",
    " [ 0.27879649,  0.22482619, -0.93711472],\n",
    " [ 0.69993199,  0.617344, 0.34889699]])\n",
    "\n",
    "R2 = np.array([[-0.75398465,  0.65677964, -0.01215072],\n",
    " [ 0.25101616,  0.27097504, -0.92928113],\n",
    " [ 0.60704039,  0.70371374,  0.36917332]]) \n",
    "\n",
    "\n",
    "# Calculamos T\n",
    "#T1 =\n",
    "#T2 = \n",
    "\n",
    "#extrinsics1 = np.zeros((3,4))\n",
    "#extrinsics1[:,:3] = R1\n",
    "#extrinsics1[:,3] = T1\n",
    "\n",
    "#extrinsics2 = np.zeros((3,4))\n",
    "#extrinsics2[:,:3] = R2\n",
    "#extrinsics2[:,3] = T2\n",
    "\n",
    "#bP1 = np.dot(K,extrinsics1)\n",
    "#bP2 = np.dot(K, extrinsics2)\n",
    "\n",
    "#b1 = cv2.imread(\"images/building/build_001.jpg\")\n",
    "#b2 = cv2.imread(\"images/building/build_003.jpg\")\n",
    "\n",
    "#bpt1, bpt2 = misc.askpoints(b1,b2)\n",
    "# reconstruct\n",
    "#mM=reconstruct(bpt1, bpt2, bP1, bP2)\n",
    "\n",
    "# convert from homog to cartesian\n",
    "#mM = mM[0:3,:] / mM[3,:]\n",
    "# plot 3D\n",
    "#misc.plot3D(mM[0,:],mM[1,:],mM[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3.**  Reproyecta los resultados de la reconstrucción\n",
    "en las dos cámaras y dibuja las proyecciones sobre las\n",
    "imágenes originales. Pinta también en otro color los puntos seleccionados manualmente. Comprueba si las proyecciones coinciden con los puntos marcados a mano. Comenta los resultados.\n",
    "Para dibujar los puntos puedes usar la función plothom\n",
    "de la práctica anterior o la versión que se distribuye con esta\n",
    "práctica (misc.plothom)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al no hacer el ejercicio 2, utilizamos los resultados del ejercicio 1 para poder hacer este ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T10:13:18.565249Z",
     "start_time": "2020-12-04T10:13:18.525249Z"
    }
   },
   "outputs": [],
   "source": [
    "# Proyecto los puntos en ambas cámaras\n",
    "proy1 = P1.dot(points3d)\n",
    "proy2 = P2.dot(points3d)\n",
    "\n",
    "# Pinto con misc.plothom()\n",
    "ppl.figure()\n",
    "misc.plothom(pt1,'bx')\n",
    "misc.plothom(proy1,'r.')\n",
    "ppl.imshow(img1)\n",
    "ppl.show()\n",
    "\n",
    "ppl.figure()\n",
    "misc.plothom(pt2,'bx')\n",
    "misc.plothom(proy2,'r.')\n",
    "ppl.imshow(img2)\n",
    "ppl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geometría epipolar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La geometría epipolar deriva de las relaciones que aparecen en las proyecciones de una escena sobre un par de\n",
    "cámaras. La matriz fundamental $\\mathbf{F}$, que depende exclusivamente de la configuración de las cámaras y no de la escena\n",
    "que éstas observan, es la representación algebráica de dicha\n",
    "geometría: a partir de ella se pueden calcular los epipolos\n",
    "y las líneas epipolares. La relación entre un par de cámaras\n",
    "$\\mathbf{P}_1$, $\\mathbf{P}_2$ y la matriz fundamental es de n -a- 1 (salvo factor de\n",
    "escala). Es decir, dadas dos cámaras calibradas, sólo tienen\n",
    "una matriz fundamental (excepto un factor de escala); dada\n",
    "una matriz fundamental existen infinitas configuraciones de\n",
    "cámaras posibles asociadas a ella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Estimación de la matriz fundamental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 4.** Implementa la función ``F = projmat2f(P1, P2)``\n",
    "que, dadas dos matrices de proyección, calcule la matriz\n",
    "fundamental asociada a las mismas. $\\mathbf{F}$ debe ser tal que,\n",
    "si $m_1$ de la imagen 1 y $m_2$ de la imagen 2 están en\n",
    "correspondencia, entonces $m_2^\\top F m_1 = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz fundamental F viene dada por la siguiente fórmula:\n",
    "\\begin{equation}\n",
    "B^{-T}[B^{-1}d-A^{-1}b]_{x}A^{-1}m\n",
    "\\end{equation}\n",
    "\n",
    "Pudiendo obtener A y b de la matriz de proyección de la cámara 1 y B y d de la matriz de proyección de la cámara 2.\n",
    "\\begin{equation}\n",
    "P_{1} = [A|b]\\\\\n",
    "P_{2} = [B|d]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projmat2f(P1,P2): \n",
    "    \"\"\" Calcula la matriz fundamental a partir de dos de proyeccion\"\"\"\n",
    "    # Descomponemos las matrices de proyección en A,B, b y d\n",
    "    A = P1[:, 0:3]\n",
    "    B = P2[:, 0:3]\n",
    "    b = P1[:, 3]\n",
    "    d = P2[:, 3]\n",
    "\n",
    "    A_ = np.linalg.inv(A)\n",
    "    B_ = np.linalg.inv(B)\n",
    "\n",
    "    B_aux = np.dot(B_,d)\n",
    "    A_aux = np.dot(A_,b)\n",
    "    aux = B_aux - A_aux\n",
    "    # Convertimos aux con la transformación vista en clase\n",
    "    aux = np.array([[0, -aux[2], aux[1]], [aux[2], 0, -aux[0]], [-aux[1], aux[0], 0]])\n",
    "    F = np.dot(np.dot(B_.T, aux), A_)\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 8.37919568e-09 -2.64352512e-06  8.61308150e-04]\n [ 8.17120624e-06  4.36740646e-06  1.37641118e-01]\n [-2.27541882e-03 -1.42176578e-01  7.61494803e-03]]\n"
     ]
    }
   ],
   "source": [
    "# compute Fundamental matrix\n",
    "F = projmat2f(P1, P2)\n",
    "# Comprobamos la mtriz\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 5** ¿Cómo es la matriz fundamental de dos cámaras\n",
    "que comparten el mismo centro? (Por ejemplo, dos cámaras\n",
    "que se diferencian sólo por una rotación.)\n",
    "\n",
    "La matriz fundamental de dos camaras con el mismo centro es una matriz compuestas por todo ceros. Básandose en la fórmula:\n",
    "$ F = [K't]_X K'RK^{-1}  $\n",
    "Si la traslación es 0, el resultado de los productos es 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Comprobación de F (OPCIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los siguientes dos ejercicios vamos a comprobar que la matriz F estimada a partir de P1 y P2 es correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 6.** Comprueba que F es la matriz fundamental asociada a las cámaras ``P1`` y ``P2``. Para ello puedes utilizar el resultado 9.12, que aparece en la página 255 del libro Hartley, Zisserman. \"Multipe View Geometry in Computer Vision.\" (sedond edition). Cambridge University Press, 2003."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como indican en el libro:\n",
    "*A non-zero matrix F is the fundamental matrix corresponding to a pair of camera matrices P and P' if and only if P'_TFP is skew-symmetric.*\n",
    "\n",
    "Si una matrix es antisimétrica, por definición:\n",
    "A + A_T = 0\n",
    "\n",
    "Entonces comprobaremos que se cumple esa propiedad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 3.76871283e-15 -7.66053887e-15 -7.10542736e-15  1.81898940e-12]\n [-7.66053887e-15 -2.82567271e-17  3.24185123e-14 -1.87583282e-12]\n [-7.10542736e-15  3.24185123e-14 -1.28541701e-13  1.09139364e-11]\n [ 1.81898940e-12 -1.87583282e-12  1.09139364e-11 -3.82231373e-09]]\n"
     ]
    }
   ],
   "source": [
    "# Seguimos el ejemplo del libro\n",
    "producto = np.dot(np.dot(P2.T,F), P1)\n",
    "\n",
    "# Si es la matrix fundamnetal, la suma del producto y su transpuesta debería ser 0\n",
    "print(producto + producto.T)\n",
    "# En este caso vemos que no sale 0 literal, pero puede ser por errores de cálculo de los tipos, aún así vemos que algunos son 0 y otros son valores muy muy pequeños cercanos a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede comprobar geométricamente la bondad de una matriz F, si  las epipolares con ella estimadas pasan por el homólogo de un punto dado en una de las imágenes.\n",
    "\n",
    "Dada la matriz fundamental $\\mathbf{F}$ entre las cámaras 1 y 2,\n",
    "se puede determinar, para un determinado punto $m_1$ en la\n",
    "imagen de la cámara 1, cuál es la recta epipolar $l_2$ donde se\n",
    "encontrará su homólogo en la cámara 2: $$l_2 = \\mathbf{F} m_1.$$\n",
    "\n",
    "Las siguientes dos funciones sirven para comprobar esta\n",
    "propiedad. En primer lugar, se necesita una función que\n",
    "dibuje rectas expresadas en coordenadas homogéneas, es\n",
    "decir, la versión de plothom para rectas en lugar de puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 7.** Implementa la función ``plothline(line)``\n",
    "que, dada una línea expresada en coordenadas homogéneas,\n",
    "la dibuje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plothline(line, axes = None):\n",
    "    \"\"\"Plot a line given its homogeneous coordinates.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    line : array_like\n",
    "        Homogeneous coordinates of the line. // ax + by + c = 0\n",
    "    axes : AxesSubplot\n",
    "        Axes where the line should be plotted. If not given,\n",
    "        line will be plotted in the active axis.\n",
    "    \"\"\"\n",
    "    if axes == None:\n",
    "        axes = ppl.gca()\n",
    "\n",
    "    #print(line)\n",
    "    \n",
    "    [x0, x1, y0, y1] = axes.axis()\n",
    "\n",
    "    #     (x0, y0) ._____________________. (x1, y0)\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #     (x0, y1) .---------------------. (x1, y1)\n",
    " \n",
    "    # Compute the intersection of the line with the image\n",
    "    # borders.\n",
    "    # Representamos las rectas de los bordes en coordenada homogéneas\n",
    "    coordenadas_izq = (1, 0, -x0)\n",
    "    coordenadas_der = (1, 0, -x1)\n",
    "    coordenadas_sup = (0, 1, -y0)\n",
    "    coordenadas_inf = (0, 1, -y1)\n",
    "\n",
    "    # Calculamos la intersección de la línea con cada borde utilizando el producto\n",
    "    corte_izq = [line[1]*coordenadas_izq[2] - coordenadas_izq[1]*line[2], coordenadas_izq[0]*line[2] - line[0]*coordenadas_izq[2], line[0]*coordenadas_izq[1] - coordenadas_izq[0]*line[1]]\n",
    "    corte_izq /= corte_izq[2]\n",
    "    corte_der = [line[1]*coordenadas_der[2] - coordenadas_der[1]*line[2], coordenadas_der[0]*line[2] - line[0]*coordenadas_der[2], line[0]*coordenadas_der[1] - coordenadas_der[0]*line[1]]\n",
    "    corte_der /= corte_der[2]\n",
    "    corte_sup = [line[1]*coordenadas_sup[2] - coordenadas_sup[1]*line[2], coordenadas_sup[0]*line[2] - line[0]*coordenadas_sup[2], line[0]*coordenadas_sup[1] - coordenadas_sup[0]*line[1]]\n",
    "    corte_sup /= corte_sup[2]\n",
    "    corte_inf = [line[1]*coordenadas_inf[2] - coordenadas_inf[1]*line[2], coordenadas_inf[0]*line[2] - line[0]*coordenadas_inf[2], line[0]*coordenadas_inf[1] - coordenadas_inf[0]*line[1]]\n",
    "    corte_inf /= corte_inf[2]\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    # Comprobamos en qué borde corta y lo añadimos al acumulador de arriba\n",
    "    if y1 <= corte_izq[1] <= y0:\n",
    "        xs += [x0]\n",
    "        ys += [corte_izq[1]]\n",
    "    if y1 <= corte_der[1] <= y0:\n",
    "        xs += [x1]\n",
    "        ys += [corte_der[1]]\n",
    "    if x0 <= corte_sup[0] <= x1:\n",
    "        y0 += [y0]\n",
    "        x0 += [corte_sup[0]]\n",
    "    if x0 <= corte_inf[0] <= x1:\n",
    "        y0 += [y1]\n",
    "        x0 += [corte_inf[0]]\n",
    "\n",
    "    # print(xs)\n",
    "    # print(ys)\n",
    "    # Plot the line with axes.plot.\n",
    "    #axes.plot(xs, ys)\n",
    "    plotline = axes.plot(xs, ys, 'r-')\n",
    "    \n",
    "    axes.axis([x0, x1, y0, y1])\n",
    "    return plotline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 8.** Completa la función ``plot_epipolar_lines(image1, image2, F)``\n",
    "que, dadas dos imágenes y la matriz fundamental que\n",
    "las relaciona, pide al usuario puntos en la imagen 1 y\n",
    "dibuje sus correspondientes epipolares en la imagen 2 usando ``plothline``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epipolar_lines(image1, image2, F):\n",
    "    \"\"\"Ask for points in one image and draw the epipolar lines for those points.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image1 : array_like\n",
    "        First image.\n",
    "    image2 : array_like\n",
    "        Second image.\n",
    "    F : array_like\n",
    "        3x3 fundamental matrix from image1 to image2.\n",
    "    \"\"\"\n",
    "    # Prepare the two images.\n",
    "    fig = ppl.gcf()\n",
    "    fig.clf()\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(image1)\n",
    "    ax1.axis('image')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(image2)\n",
    "    ax2.axis('image')\n",
    "    ppl.draw()\n",
    "    \n",
    "    ax1.set_xlabel(\"Choose points in left image (or right click to end)\")\n",
    "    point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    while len(point) != 0:\n",
    "        # point has the coordinates of the selected point in the first image.\n",
    "        point = np.hstack([np.array(point[0]), 1])\n",
    "        ax1.plot(point[0], point[1], '.r')\n",
    "        \n",
    "        # Determine the epipolar line.\n",
    "        # Por definición la linea epipolar es la multiplicación de F por el punto\n",
    "        line = np.dot(F, point)\n",
    "        \n",
    "        # Plot the epipolar line with plothline (the parameter 'axes' should be ax2).\n",
    "        plothline(line, axes=ax2)\n",
    "        \n",
    "        ppl.draw()\n",
    "        # Ask for a new point.\n",
    "        point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    \n",
    "    ax1.set_xlabel('')\n",
    "    ppl.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza esta función con un par de imágenes llamándola\n",
    "de dos formas diferentes: seleccionando puntos en la imagen\n",
    "izquierda y dibujando las epipolares en la imagen derecha\n",
    "y viceversa. Comprueba en ambos casos que las epipolares\n",
    "siempre pasan por el punto de la segunda imagen correspondiente al seleccionado en la primera. Esto confirmara la corrección de la matriz F.\n",
    "\n",
    "Añade dos figuras una que muestre la selección de puntos en\n",
    "la imagen izquierda y las rectas correspondientes en la\n",
    "imagen derecha, y otra que lo haga al revés. Indica para\n",
    "ambos casos qué matriz fundamental has usado al llamar a\n",
    "``plot_epipolar_lines``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Para representar las rectas de puntos de la imagen 1 en la imagen 2 usamos la matriz F.\n",
    "plot_epipolar_lines(img1, img2, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para representar las rectas de puntos de la imagen 2 en la imagen 1 usamos la matriz rtanspuesa de F.\n",
    "plot_epipolar_lines(img2, img1, np.transpose(F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Rectificación de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es recomendable trabajar a partir de ahora con imágenes\n",
    "en blanco y negro y con valores reales entre 0 y 1 para cada\n",
    "uno de sus píxeles. Eso se puede conseguir con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = misc.rgb2gray(img1/255.0)\n",
    "img2 = misc.rgb2gray(img2/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoría de algoritmos de puesta en correspondencia,\n",
    "incluyendo el que se va a implementar en esta práctica,\n",
    "requieren que las imágenes de entrada estén rectificadas.\n",
    "\n",
    "Dos imágenes están rectificadas si sus correspondientes epipolares están alineadas horizontalmente. La rectificación de\n",
    "imágenes facilita enormemente los algoritmos de puesta en\n",
    "correspondencia, que pasan de ser problemas de búsqueda\n",
    "bidimensional a problemas de búsqueda unidimensional\n",
    "sobre filas de píxeles de las imágenes. En el material de\n",
    "la práctica se han incluido dos funciones que rectifican\n",
    "(mediante un método lineal) dos imágenes. La función\n",
    "``H1, H2 = misc.projmat2rectify(P1, P2, imsize)``\n",
    "devuelve, dadas las dos matrices de proyección y el tamaño de las imágenes en formato (filas,columnas), las\n",
    "homografías que rectifican, respectivamente, la imagen 1\n",
    "y la imagen 2. La función ``projmat2rectify`` hace uso\n",
    "de ``projmat2f``, por lo que\n",
    "es necesario que esta función esté disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 9.** Se tienen dos imágenes no rectificadas ``im1`` e\n",
    "``im2``, y su matriz fundamental asociada $\\mathbf{F}$ . Con el procedimiento explicado, se encuentran un par de homografías $\\mathbf{H}_1$ y $\\mathbf{H}_2$ que dan lugar a las imágenes rectificadas ``O1`` y ``O2``. ¿Cuál es la matriz fundamental $\\mathbf{F}′$ asociada a estas dos imágenes? ¿Por qué?\n",
    "\n",
    "Nota: F ′ depende exclusivamente de F , H1 y H2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz fundamental F' es:\n",
    "\n",
    "$ F' = H^{-T}_2 F H^{-1}_1 $\n",
    "\n",
    "Esta relación entre ambas matrices fundamentales está extraída de la página 253 del libro de Hartley y Zisserman."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 10.** Rectifica el par de imágenes estéreo ``img1`` e ``img2`` y calcula\n",
    "la matriz fundamental asociada a estas imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homografías\n",
    "H1, H2 = misc.projmat2rectify(P1, P2, projmat2f, img1.shape)\n",
    "# Imágens rectificadas\n",
    "O1, O2 = misc.rectify_images(img1, img2, H1, H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e3c0b35208>"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "# Mostramos las imágenes rectificadas\n",
    "ppl.figure()\n",
    "ppl.imshow(O1)\n",
    "ppl.figure()\n",
    "ppl.imshow(O2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 11.** Calcula y muestra la matriz fundamental de las imágenes\n",
    "rectificadas. Justifica el resultado obtenido (mira la sección 9.3.1 del libro de Hartley y Zisserman, pág. 248 y 249)."
   ]
  },
  {
   "source": [
    "Aplicamos la fórmula del ejercicio 9 y comprobamos que la matriz tiene la forma siguiente:\n",
    "\n",
    "0 0 0\n",
    "\n",
    "0 0 -1\n",
    "\n",
    "0 1 0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 4.17470918e-22, -4.15104069e-17,  5.22305036e-15],\n",
       "       [ 4.57185342e-17,  7.20057323e-18, -1.00000000e+00],\n",
       "       [-5.37014259e-15,  1.00000000e+00,  6.14597487e-13]])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "Fr=np.dot(np.dot(np.linalg.inv(H2.transpose()), F), np.linalg.inv(H1))\n",
    "Fr=Fr/Fr[2,1]\n",
    "Fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 12.** Usa ``plot_epipolar_lines`` para dibujar varias líneas epiplares de las imágenes rectificadas. Muestra los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos la matriz\n",
    "plot_epipolar_lines(O1, O2, Fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Búsqueda de correspondencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda de correspondencias consigue establecer automáticamente las correspondencias de puntos entre dos\n",
    "imágenes (lo que se ha hecho manualmente en el ejercicio 2)\n",
    "haciendo uso de las restricciones que proporciona la geometría epipolar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Cálculo de las medidas de similaridad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez rectificadas las dos imágenes de un par estéreo,\n",
    "se pueden buscar las correspondencias. Una matriz de disparidades $\\mathbf{S}$ indica, para cada píxel de la imagen 1\n",
    "rectificada, a cuántos píxeles de diferencia está su correspondencia\n",
    "en la imagen 2 rectificada. En nuestra práctica, para simplificar el problema, vamos a considerar que los elementos\n",
    "de $\\mathbf{S}$ son enteros. Para el píxel en la posición $(x, y)$ en la\n",
    "imagen 1, su correspondiente está en $(x + S[y, x], y)$ en la\n",
    "imagen 2. Si $S[y, x] < 0$, la correspondencia está hacia la\n",
    "izquierda; si $S[y, x] > 0$, la correspondencia está hacia la\n",
    "derecha; si $S[y, x] = 0$, las coordenadas de los dos puntos\n",
    "coinciden en ambas imágenes.\n",
    "\n",
    "La búsqueda de correspondencias requiere ser capaz de\n",
    "determinar el parecido visual entre píxeles de dos imágenes.\n",
    "Si los píxeles $m_1$ y $m_2$ son visualmente parecidos, tienen\n",
    "más probabilidad de estar en correspondencia que otros\n",
    "que sean visualmente diferentes. Como la\n",
    "apariencia (el nivel de gris) de un único píxel es propensa\n",
    "al ruido y poco discriminativa, el elemento de puesta en\n",
    "correspondencia será una ventana centrada en el píxel.\n",
    "Dado un píxel $m$ de una imagen, llamaremos vecindad\n",
    "del píxel de radio $K$ al conjunto de píxeles de la imagen que se encuentren dentro de una ventana de tamaño\n",
    "$(2K + 1) × (2K + 1)$ píxeles centrada en $m$ . El número de\n",
    "píxeles de una vecindad de radio $K$ es $N = (2K + 1)^2$.\n",
    "Dadas dos vecindades $w_1$ y $w_2$ de dos píxeles, el parecido\n",
    "visual entre ellas puede calcularse con la suma de *diferencias\n",
    "al cuadrado (SSD)* de cada una de sus componentes\n",
    "$$d_{SSD}(\\mathbf{v}, \\mathbf{w}) = \\sum_{i=1}^N(\\mathbf{v}_i - \\mathbf{w}_i)^2.$$\n",
    "\n",
    "La distancia $d_{SSD}$ es siempre positiva, es pequeña cuando\n",
    "dos ventanas son visualmente parecidas y grande en caso\n",
    "contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 13.** Implementa la función\n",
    "``C = localssd(im1, im2, K)``\n",
    "que calcula la suma de diferencias al cuadrado entre las\n",
    "ventanas de radio K de la imagen 1 y la imagen 2. El\n",
    "resultado debe ser una matriz del mismo tamaño que las\n",
    "imágenes de entrada que contenga en cada punto el valor\n",
    "de $d_{SSD}$ para la ventana de la imagen 1 y la ventana\n",
    "de la imagen 2 centradas en él. Es decir, $C[i,j]$ debe\n",
    "ser el resultado de $d_{SSD}$ para las ventanas centradas en\n",
    "$im1[i,j]$ e $im2[i,j]$.\n",
    "\n",
    "Para este ejercicio puede resultar útil la función\n",
    "``scipy.ndimage.convolve``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localssd(im1, im2, K):\n",
    "    \"\"\"\n",
    "    The local sum of squared differences between windows of two images.\n",
    "    \n",
    "    The size of each window is (2K+1)x(2K+1).\n",
    "    \"\"\"\n",
    "    conv = np.ones(shape=(2*K+1, 2*K+1))\n",
    "    diff = np.power(im2 - im1, 2)\n",
    "\n",
    "    return scnd.convolve(diff, conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e3c224ab88>"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "# Calculamos la suma de diferencias al cuadrado\n",
    "ret = localssd(O1, O2, 5)\n",
    "\n",
    "# Ploteamos\n",
    "ppl.figure()\n",
    "ppl.imshow(ret, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 14.** Implementa la función ``D = ssd_volume(im1, im2, disps, K)`` que calcula la suma de diferencias al cuadrado entre las\n",
    "ventanas de la imagen ``im1`` y la imagen ``im2`` desplazada\n",
    "horizontalmente. El parámetro ``disps`` debe ser una lista\n",
    "de valores indicando las disparidades que se usarán para desplazar la imagen ``im2``. Por ejemplo, si ``disps`` es\n",
    "``np.arange(-3,2)``, se llamará 5 veces a ``localssd`` para la\n",
    "imagen 1 y la imagen 2 desplazada −3 , −2 , −1 , 0 y 1 píxeles\n",
    "en sentido horizontal. K es el parámetro que indica el radio\n",
    "de las ventanas usado por localssd.\n",
    "\n",
    "El valor devuelto D será un array de tamaño $M × N × L$,\n",
    "donde L es el número de disparidades indicadas por ``disps``,\n",
    "``L = len(disps)`` (es decir, el número de veces que se ha\n",
    "llamado a ``localssd``); M y N son, respectivamente, el\n",
    "número de filas y de columnas de las imágenes de entrada.\n",
    "El elemento ``D[y,x,l]`` debe ser la SSD entre la ventana\n",
    "centrada en ``im1[y,x]`` y la ventana centrada en ``im2[y,x + disps[l]]``.\n",
    "\n",
    "``D[y,x,l]`` debe ser muy grande para aquellos valores en\n",
    "los que ``im2[y,x + disps[l]]`` no esté definido, es decir,\n",
    "el índice``(y,x+disps[l])`` se sale de la imagen 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_volume(im1, im2, disps, K):\n",
    "    \"\"\"\n",
    "    Calcula el volumen de disparidades SSD\n",
    "    \"\"\"\n",
    "    D = np.zeros(shape=(np.shape(im1)[0],np.shape(im1)[1],len(disps)))\n",
    "    for d in range(len(disps)):\n",
    "        img_desp = np.zeros(im2.shape)\n",
    "        img_desp[:,:-disps[d]:] = im2[:,disps[d]:]\n",
    "        D[:,:,d] = localssd(im1, img_desp, K)\n",
    "        \n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 15.** El conjunto de disparidades ``disps`` debe ser lo más pequeño posible, para mejorar el rendimiento de la optimización. Determina un procedimiento para estimar manualmente el conjunto de disparidades posibles y aplícalo a las imágenes O1 y O2.\n",
    "\n",
    "Para derterminar que conjunto de disparidades se iba a emplear se mostraron las dos imágenes por pantalla y de forma aproximada se apuntó la posición X de un punto en la imágen 1 y la posición X' de un punto en la imágen 2. Al analizar la diferencia entre los valores de X y X' se observó como había una diferencia entorno a 170-180 píxeles por lo que este conjunto de disparidades debe de contener al menos estos valores obtenidos de las diferencias. Como se trata de un proceso manual y no muy preciso, se añadio un margen superior e inferior de 20 pixeles más, por lo que el conjunto de disparidades irá desde 150 (20 pixeles menos que 170) hasta 200 (20 pixeles por encima de 180)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "disps = np.arange(150, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica la función ``ssd_volume`` al par de imágenes O1 y O2\n",
    "con las disparidades estimadas en el ejercicio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e3b1914988>"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "D = ssd_volume(O2, O1, disps, 5)\n",
    "\n",
    "# to speed-up the optimization ahead, discard the par of the image showing only background\n",
    "\n",
    "# Mostramos la correspondiente a 14, es decir, 164 de desplazamiento\n",
    "ppl.figure()\n",
    "ppl.imshow(D[:,:,14], cmap='gray')\n",
    "\n",
    "#ppl.figure()\n",
    "#ppl.imshow(D[:,200,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Estimación de la disparidad sin regularizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz D calculada en el ejercicio anterior proporciona\n",
    "los costes unitarios $D_i$ de una función de energía sin regularización de la forma $$E(x) = \\sum_{i} D_i(x_i),$$\n",
    "donde $D_i(l)$ viene dado por $D[y,x,l]$, suponiendo que\n",
    "el píxel $i$ tenga coordenadas $(x, y)$. Las variables \n",
    "$x = (x_1 ,\\ldots, x_{NM})$ indican las etiquetas de cada uno de los\n",
    "píxeles. En este caso, las etiquetas son los índices del\n",
    "array ``disps``, que a su vez son las disparidades horizontales.\n",
    "Por eso, a partir de aquí se hablará indistintamente de\n",
    "etiquetas y disparidades. Sólo es necesario recordar que la\n",
    "etiqueta $l$ está asociada a la disparidad ``disps[l]``.\n",
    "\n",
    "\n",
    "Minimizando la energía $x = \\arg\\min_x E(x)$,\n",
    "se obtiene un vector de etiquetas óptimo $x^*$ que indica, para\n",
    "cada píxel, cuál es su disparidad horizontal entre las dos\n",
    "imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 16.** Minimiza $E(x)$ y muestra las disparidades resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1e3bdf4a248>"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "# El valor mínimo se puede obtener directamente con argmin\n",
    "res = D.argmin(axis=2)\n",
    "ppl.figure()\n",
    "ppl.imshow(res,cmap='gray')\n",
    "ppl.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Estimación de la disparidad regularizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El etiquetado usando exclusivamente términos unitarios\n",
    "es muy sensible al ruido y propenso a que aparezcan zonas\n",
    "de píxeles cercanos con mucha variación en las etiquetas.\n",
    "Esto es especialmente notable en zonas planas (es decir, sin\n",
    "textura) de las imágenes originales, donde no hay suficiente\n",
    "información para establecer una correspondencia basándose\n",
    "exclusivamente en la apariencia visual de ventanas pequeñas. Por eso es necesario incluir un término de suavizado\n",
    "o regularización en la función de energía. Los tipos de\n",
    "saltos de etiquetas que aparecerán en el resultado final\n",
    "dependerán de cómo sea ese término de suavizado.\n",
    "\n",
    "La función de energía que utilizaremos para calcular\n",
    "las disparidades en la práctica será el resultado de añadir\n",
    "a la expresión (6) un término que penalice los cambios de\n",
    "disparidad en los píxeles vecinos: $$E_r(x) = \\sum_{i} D_i(x_i) + \\lambda\\sum_{ij} \\min(k,|x_i-x_j|).$$ Siendo $j$ los índices de los píxeles vecinos del $i$ en la imagen.\n",
    "La solución al problema de la correspondencia vendrá dado\n",
    "por el conjunto de etiquetas (disparidades) de los píxeles de\n",
    "la imagen que minimicen $E_r(x)$.\n",
    "\n",
    "En [Yuri Boykov, Olga Veksler, and Ramin Zabih. \"Fast approximate\n",
    "energy minimization via graph cuts\". *IEEE Transactions on Pattern\n",
    "Analysis and Machine Intelligence*, 23:1222–1239, 2001.] se presentan métodos para resolver algunos problemas de optimización con varias etiquetas empleando\n",
    "algoritmos de cortes de grafos. Es recomendable repasar las\n",
    "secciones 5 y 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 17.** Escribe la función ``find_corresp_aexpansion(D, initLabels, lmb, maxV)``,\n",
    "que recibe un volumen ssd, ``D``, un conjunto inicial de\n",
    "etiquetas, ``initLabels``, que puede ser el obtenido en el\n",
    "ejercicio 5, el valor de la constante $\\lambda$, y el valor máximo\n",
    "de la función de coste $|x_i − x_j|$, que tendrás que establecer empíricamente. El resultado de esta función serán las\n",
    "etiquetas que minimizan $E_r(x)$. Para ello debes utilizar la función ``maxflow.fastmin.aexpansion_grid(D, V, max_cycles=None, labels=None)`` del paquete\n",
    "*PyMaxFlow*, que resuelve el problema anterior mediante un\n",
    "algoritmo de cortes de grafos empleando una $\\alpha$-expansión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corresp_aexpansion(D, initialLabels, lmb, maxV):\n",
    "    return maxflow.fastmin.aexpansion_grid(D, lmb*maxV, max_cycles=None, labels=initialLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama a esta función y muestra una figura con las etiquetas que resulten de la minimización de la energía para el volumen ssd ``D`` (este proceso puede durar varios minutos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = D.shape[-1]\n",
    "X,Y = np.mgrid[:len(disps), :len(disps)]\n",
    "V = 2 * np.float_(np.abs(X-Y))\n",
    "labels = find_corresp_aexpansion(D, res, .5, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e3bd86d0c8>"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "ppl.figure()\n",
    "ppl.imshow(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo aexpansión utilizado utiliza un etiquetado inicial, que en este caso es el que se obtuvo del ejercicio 16 al minimizar la función de energía y una matriz V para la energía smooth. En este caso esta matriz V se calculo mediante el producto de un valor lambda y una matriz de diferencias. El valor de lambda se estimó empiricamente mediante diferentes pruebas y observando cual era el mejor valor obtenido. La matriz de diferencias se calculo haciendo la diferencia de dos matrices, X e Y. X es una matriz en la que cada fila contiene el índice de un valor de disparidad y todos los valores de esa fila son idénticos. Y es matriz similar a la anterior pero en este caso todos los valores de una misma columna son ideénticos y representan una posición de disparidades. Para entender este concepto mejor, si hubiese 3 disparidades (que son las obtenidas empiricamente en el ejercicio 15), las matrices serían\n",
    "$$\n",
    "X = \n",
    "\\begin{matrix}\n",
    "     0 & 0 & 0\\\\\n",
    "     1 & 1 & 1\\\\\n",
    "     2 & 2 & 2\n",
    "\\end{matrix},\n",
    "Y = \n",
    "\\begin{matrix}\n",
    "     0 & 1 & 2\\\\\n",
    "     0 & 1 & 2\\\\\n",
    "     0 & 1 & 2\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Ésta definción de la matriz V se obtuvo de la propia librería PyMaxFlow, ya que un resolvedor de esterográmas implementado en la librería define la matriz V tal y como la definimos nosotros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de etiquetas óptimas X obtenida de la minimización de la función de energía puede transformarse en\n",
    "la matriz de disparidades S indexando en cada una de sus\n",
    "celdas el array de disparidades disps ``S = disps[X]``.\n",
    "Ahora, el píxel de coordenadas (x, y) de la primera imagen\n",
    "rectificada tendrá su correspondencia en el píxel de coordenadas (x + S [y, x], y) de la segunda imagen rectificada.\n",
    "\n",
    "El siguiente ejercicio usa la matriz de disparidades para\n",
    "establecer automáticamente las correspondencias entre un\n",
    "par de imágenes sin rectificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 18.** Implementa la función\n",
    "``plot_correspondences(image1, image2, S, H1,H2)``\n",
    "que, dado un par de imágenes sin rectificar, la matriz de\n",
    "disparidades entre las imágenes rectificadas y las homogra-\n",
    "fías que llevan de las imágenes sin rectificar a las imágenes\n",
    "rectificadas, pida al usuario puntos en la primera imagen y\n",
    "dibuje sus correspondencias en la segunda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correspondences(image1, image2, S, H1, H2):\n",
    "    \"\"\"\n",
    "    Ask for points in the first image and plot their correspondences in\n",
    "    the second image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image1, image2 : array_like\n",
    "        The images (before rectification)\n",
    "    S : array_like\n",
    "        The matrix of disparities.\n",
    "    H1, H2 : array_like\n",
    "        The homographies which rectify both images.\n",
    "    \"\"\"\n",
    "    # Prepare the two images.\n",
    "    fig = ppl.gcf()\n",
    "    fig.clf()\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(image1)\n",
    "    ax1.axis('image')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(image2)\n",
    "    ax2.axis('image')\n",
    "    ppl.draw()\n",
    "    \n",
    "    ax1.set_xlabel(\"Choose points in left image (or right click to end)\")\n",
    "    point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    while len(point) != 0:\n",
    "        # point has the coordinates of the selected point in the first image.\n",
    "        point = np.c_[np.array(point), 1].T\n",
    "        ax1.plot(point[0,:], point[1,:], '.r')\n",
    "        \n",
    "        # Determine the correspondence of 'point' in the second image.\n",
    "        # perhaps you have to swap the image co-ordinates.\n",
    "        punto1_rectificado = np.dot(H1, point)\n",
    "        punto1_rectificado /= punto1_rectificado[2]\n",
    "        punto2_rectificado = [punto1_rectificado[0] - S[int(punto1_rectificado[1]), int(punto1_rectificado[0])], punto1_rectificado[1], 1.]\n",
    "        punto2 = np.dot(np.linalg.inv(H2), punto2_rectificado)\n",
    "        punto2 /= punto2[2]\n",
    "        \n",
    "        \n",
    "        # Plot the correspondence with ax2.plot.\n",
    "        ax2.plot(punto2[0], punto2[1] ,'r.')\n",
    "        \n",
    "        ppl.draw()\n",
    "        # Ask for a new point.\n",
    "        point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    \n",
    "    ax1.set_xlabel('')\n",
    "    ppl.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = disps[labels]\n",
    "plot_correspondences(img1, img2, S, H1, H2)"
   ]
  },
  {
   "source": [
    "Podemos comprobar como para puntos situados en la cara izquierda del cubo la búsqueda de correspondencias funciona bastante bien. Sin embargo, con las esquinas funciona bastante peor así como con la cara izquierda del cubo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "05fc9de2ad11545762000b0728d4c1e075b7d9e4b8f7609ef89ebb417cfe0cad"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}