{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The German Traffic Sign Benchmark\n",
    "\n",
    "Student Name 1: ...\n",
    "\n",
    "Student Name 2: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data base\n",
    "!wget -c http://www.dia.fi.upm.es/~lbaumela/FullIJCNN2013.zip\n",
    "!unzip FullIJCNN2013.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "IMG_HEIGHT = 600\n",
    "SIGN_SIZE = (224, 224)\n",
    "\n",
    "# Function for reading the images\n",
    "def readImages(rootpath, images_range, signs_range):\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "    Arguments: path to the traffic sign data, for example 'FullIJCNN2013'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = {} # original image\n",
    "    scales = {} # original scale\n",
    "    for num in images_range:\n",
    "        filename = rootpath + '/' + \"{:05d}\".format(num) + '.ppm'\n",
    "        img = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "        scale = IMG_HEIGHT / float(img.shape[0])\n",
    "        img_resized = cv2.resize(img, (int(img.shape[1]*scale),int(img.shape[0]*scale)))\n",
    "        images.setdefault(filename,[]).append(img_resized)\n",
    "        scales.setdefault(filename,[]).append(scale)\n",
    "\n",
    "    files = [] # filenames\n",
    "    signs = [] # traffic sign image\n",
    "    bboxes = [] # corresponding box detection\n",
    "    labels = [] # traffic sign type\n",
    "    data = np.genfromtxt(rootpath + '/' + 'gt.txt', delimiter=';', dtype=str, usecols=range(0, 6))\n",
    "    for elem in signs_range:\n",
    "        filename = rootpath + '/' + data[elem][0]\n",
    "        img = images.get(filename)[0]\n",
    "        scale = scales.get(filename)[0]\n",
    "        bbox = np.array([int(data[elem][1]), int(data[elem][2]), int(data[elem][3]), int(data[elem][4])]) * scale\n",
    "        sign = img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "        sign_resized = cv2.resize(sign, SIGN_SIZE)\n",
    "        files.append(filename)\n",
    "        signs.append(sign_resized)\n",
    "        bboxes.append(bbox)\n",
    "        labels.append(data[elem][5])\n",
    "    return images, files, signs, bboxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The German Traffic Sign Recognition Benchmark\n",
    "train_images, train_files, train_signs, train_bboxes, train_labels = readImages('FullIJCNN2013', range(0,600), range(0,852))\n",
    "test_images, test_files, test_signs, test_bboxes, test_labels = readImages('FullIJCNN2013', range(600,900), range(852,1213))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Show examples from each class\n",
    "class_names = np.unique(train_labels)\n",
    "num_classes = len(class_names)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(6, 9, 1 + i, xticks=[], yticks=[])\n",
    "    ax.set_title(class_names[i])\n",
    "    indices = np.where(np.isin(train_labels, class_names[i]))[0]\n",
    "    plt.imshow(cv2.cvtColor(train_signs[int(np.random.choice(indices, 1))], cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_files, train_signs, train_bboxes, train_labels = shuffle(train_files, train_signs, train_bboxes, train_labels)\n",
    "# plt.imshow(cv2.cvtColor(train_images.get(train_files[0])[0], cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "# plt.imshow(cv2.cvtColor(train_signs[0], cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "# print(train_bboxes[0])\n",
    "# print(train_labels[0])\n",
    "\n",
    "# Data pre-processing\n",
    "tr_signs = np.array(train_signs)[0:600]\n",
    "tr_labels = np.array(train_labels)[0:600]\n",
    "va_signs = np.array(train_signs)[600:852]\n",
    "va_labels = np.array(train_labels)[600:852]\n",
    "te_signs = np.array(test_signs)\n",
    "te_labels = np.array(test_labels)\n",
    "\n",
    "tr_signs = tr_signs.astype('float32')\n",
    "va_signs = va_signs.astype('float32')\n",
    "te_signs = te_signs.astype('float32')\n",
    "tr_signs /= 255.0\n",
    "va_signs /= 255.0\n",
    "te_signs /= 255.0\n",
    "\n",
    "from keras.utils import np_utils\n",
    "tr_labels = np_utils.to_categorical(tr_labels, num_classes)\n",
    "va_labels = np_utils.to_categorical(va_labels, num_classes)\n",
    "te_labels = np_utils.to_categorical(te_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1: Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras import optimizers\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Flatten(input_shape=(SIGN_SIZE[0], SIGN_SIZE[1], 3)))\n",
    "mlp.add(Dense(80))\n",
    "mlp.add(Activation('relu'))\n",
    "mlp.add(Dense(num_classes))\n",
    "mlp.add(Activation('softmax'))\n",
    "\n",
    "opt = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "mlp.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mlp.fit(tr_signs, tr_labels, batch_size=16, epochs=100, verbose=2, validation_data=(va_signs, va_labels), callbacks=[tensorboard])\n",
    "\n",
    "start = time()\n",
    "loss, acc = mlp.evaluate(te_signs, te_labels, verbose=0)\n",
    "end = time()\n",
    "print('MLP took ' + str(end - start) + ' seconds')\n",
    "print('Test loss: ' + str(loss) + ' - Accuracy: ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
